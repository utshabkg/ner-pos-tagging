{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Token    POS    NER\n",
      "0   শনিবার (২৭ আগস্ট) রাতে পটুয়াখালী সদর থানার ভা...    NaN    NaN\n",
      "1                                              শনিবার    NNP  B-D&T\n",
      "2                                                 (২৭  PUNCT  B-OTH\n",
      "3                                              আগস্ট)    NNP  B-D&T\n",
      "4                                                রাতে    NNC  B-D&T\n",
      "5                                          পটুয়াখালী    NNP  B-GPE\n",
      "6                                                 সদর    NNC  I-GPE\n",
      "7                                               থানার    NNC  I-GPE\n",
      "8                                          ভারপ্রাপ্ত    ADJ  B-PER\n",
      "9                                           কর্মকর্তা    NNC  I-PER\n",
      "10                                              (ওসি)  PUNCT  B-OTH\n",
      "11                                               মো.    NNP  B-PER\n",
      "12                                       মনিরুজ্জামান    NNP  I-PER\n",
      "13                                                  এ    DET  B-OTH\n",
      "14                                               তথ্য    NNC  B-OTH\n",
      "15                                            নিশ্চিত    ADJ  B-OTH\n",
      "16                                            করেছেন।     VF  B-OTH\n",
      "17                                                NaN    NaN    NaN\n",
      "18  বায়ুদূষণ ও স্মার্ট ফোন ছেলেমেয়ে উভয়ের প্রজনন ক...    NaN    NaN\n",
      "19                                           বায়ুদূষণ    NNC  B-OTH\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'dataset/data.tsv'\n",
    "data = pd.read_csv(file_path, sep='\\t', header=None, names=['Token', 'POS', 'NER'], skip_blank_lines=False)\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53438, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token    4054\n",
       "POS      8112\n",
       "NER      8114\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in the raw dataset: 4054\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique sentences\n",
    "# A sentence is identified by rows where Token, POS and NER are NaN\n",
    "blank_rows = data[data['Token'].isna() & data['POS'].isna() & data['NER'].isna()].shape[0]\n",
    "\n",
    "print(f\"Number of sentences in the raw dataset: {blank_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token       0\n",
       "POS      4058\n",
       "NER      4060\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned = data.dropna(how='all')\n",
    "data_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "missing_values = data_cleaned.isna().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4058"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sentences = data_cleaned[data_cleaned['POS'].isna() & data_cleaned['NER'].isna()].shape[0]\n",
    "num_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>POS</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49379</th>\n",
       "      <td>সফর</td>\n",
       "      <td>NNC</td>\n",
       "      <td>B-OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49380</th>\n",
       "      <td>বিনিময়ের</td>\n",
       "      <td>NNC</td>\n",
       "      <td>B-OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49381</th>\n",
       "      <td>উপর</td>\n",
       "      <td>PP</td>\n",
       "      <td>B-OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49382</th>\n",
       "      <td>গুরুত্বারোপ</td>\n",
       "      <td>NNC</td>\n",
       "      <td>B-OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49383</th>\n",
       "      <td>করেন।</td>\n",
       "      <td>VF</td>\n",
       "      <td>B-OTH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Token  POS    NER\n",
       "49379           সফর  NNC  B-OTH\n",
       "49380     বিনিময়ের  NNC  B-OTH\n",
       "49381           উপর   PP  B-OTH\n",
       "49382  গুরুত্বারোপ  NNC  B-OTH\n",
       "49383         করেন।   VF  B-OTH"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>POS</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>শনিবার (২৭ আগস্ট) রাতে পটুয়াখালী সদর থানার ভা...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>বায়ুদূষণ ও স্মার্ট ফোন ছেলেমেয়ে উভয়ের প্রজনন ক...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ছাত্র রাজনীতির বর্তমান অবস্থার শুরু হয়েছিলো ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>শাকিল রাজধানীর ৩০০ ফিট, দিয়াবাড়ি ও পূর্বাচল ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>সম্প্রতি ক্লাবের নবীন ব্যবস্থাপনা প্রশিক্ষণার্...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Token  POS  NER\n",
       "0   শনিবার (২৭ আগস্ট) রাতে পটুয়াখালী সদর থানার ভা...  NaN  NaN\n",
       "17  বায়ুদূষণ ও স্মার্ট ফোন ছেলেমেয়ে উভয়ের প্রজনন ক...  NaN  NaN\n",
       "29  ছাত্র রাজনীতির বর্তমান অবস্থার শুরু হয়েছিলো ...  NaN  NaN\n",
       "40  শাকিল রাজধানীর ৩০০ ফিট, দিয়াবাড়ি ও পূর্বাচল ...  NaN  NaN\n",
       "57  সম্প্রতি ক্লাবের নবীন ব্যবস্থাপনা প্রশিক্ষণার্...  NaN  NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display rows where 'POS' or 'NER' are NaN\n",
    "rows_with_missing_tags = data_cleaned[data_cleaned['POS'].isna() | data_cleaned['NER'].isna()]\n",
    "rows_with_missing_tags.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token    0\n",
       "POS      0\n",
       "NER      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing values in 'POS' and 'NER' with 'UNKNOWN'\n",
    "data_cleaned = data_cleaned.dropna(subset=['POS', 'NER'])\n",
    "\n",
    "missing_values_filled = data_cleaned.isna().sum()\n",
    "missing_values_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>POS</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>শনিবার</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-D&amp;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(২৭</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>B-OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>আগস্ট)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-D&amp;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>রাতে</td>\n",
       "      <td>NNC</td>\n",
       "      <td>B-D&amp;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>পটুয়াখালী</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Token    POS    NER\n",
       "1      শনিবার    NNP  B-D&T\n",
       "2         (২৭  PUNCT  B-OTH\n",
       "3      আগস্ট)    NNP  B-D&T\n",
       "4        রাতে    NNC  B-D&T\n",
       "5  পটুয়াখালী    NNP  B-GPE"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45324, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Tokens:\n",
      "ও           442\n",
      "বলেন,       321\n",
      "থেকে        285\n",
      "এ           268\n",
      "করে         251\n",
      "করা         228\n",
      "এই          215\n",
      "এবং         174\n",
      "জন্য        168\n",
      "তিনি        160\n",
      "এক          159\n",
      "একটি        155\n",
      "হয়েছে।     130\n",
      "করতে        129\n",
      ":           126\n",
      "বাংলাদেশ    110\n",
      "না          109\n",
      "হবে।        106\n",
      "মধ্যে       105\n",
      "হয়।        103\n",
      "Name: Token, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Distribution of tokens\n",
    "token_distribution = data_cleaned['Token'].value_counts()\n",
    "print(\"Top 20 Tokens:\")\n",
    "print(token_distribution.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tag Distribution:\n",
      "NNC      17803\n",
      "NNP       7544\n",
      "ADJ       4581\n",
      "VF        4417\n",
      "QF        1971\n",
      "PP        1866\n",
      "VNF       1602\n",
      "ADV       1461\n",
      "PRO       1329\n",
      "CONJ       947\n",
      "PUNCT      859\n",
      "DET        773\n",
      "PART        85\n",
      "OTH         67\n",
      "INTJ        19\n",
      "Name: POS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Distribution of POS tags\n",
    "pos_distribution = data_cleaned['POS'].value_counts()\n",
    "print(\"POS Tag Distribution:\")\n",
    "print(pos_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Tag Distribution:\n",
      "B-OTH      30932\n",
      "B-PER       3565\n",
      "B-ORG       1575\n",
      "I-PER       1426\n",
      "B-NUM       1314\n",
      "I-ORG       1151\n",
      "B-GPE        997\n",
      "B-D&T        996\n",
      "I-D&T        787\n",
      "B-EVENT      551\n",
      "B-LOC        460\n",
      "B-UNIT       301\n",
      "I-NUM        277\n",
      "I-EVENT      253\n",
      "B-MISC       249\n",
      "I-LOC        232\n",
      "B-T&T        106\n",
      "I-T&T         52\n",
      "I-GPE         51\n",
      "I-MISC        37\n",
      "I-UNIT        12\n",
      "Name: NER, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Distribution of NER tags\n",
    "ner_distribution = data_cleaned['NER'].value_counts()\n",
    "print(\"NER Tag Distribution:\")\n",
    "print(ner_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infrequent POS Tags:\n",
      "Index([], dtype='object')\n",
      "Infrequent NER Tags:\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Define a threshold for infrequent tags (e.g., less than a certain count)\n",
    "threshold = 5\n",
    "\n",
    "# Identify infrequent POS tags\n",
    "infrequent_pos_tags = pos_distribution[pos_distribution < threshold].index\n",
    "\n",
    "# Identify infrequent NER tags\n",
    "infrequent_ner_tags = ner_distribution[ner_distribution < threshold].index\n",
    "\n",
    "print(\"Infrequent POS Tags:\")\n",
    "print(infrequent_pos_tags)\n",
    "\n",
    "print(\"Infrequent NER Tags:\")\n",
    "print(infrequent_ner_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>POS</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>শনিবার</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-D&amp;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(২৭</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>B-OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>আগস্ট)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-D&amp;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>রাতে</td>\n",
       "      <td>NNC</td>\n",
       "      <td>B-D&amp;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>পটুয়াখালী</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Token    POS    NER\n",
       "0      শনিবার    NNP  B-D&T\n",
       "1         (২৭  PUNCT  B-OTH\n",
       "2      আগস্ট)    NNP  B-D&T\n",
       "3        রাতে    NNC  B-D&T\n",
       "4  পটুয়াখালী    NNP  B-GPE"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with infrequent POS or NER tags\n",
    "data_cleaned = data_cleaned[~data_cleaned['POS'].isin(infrequent_pos_tags) & ~data_cleaned['NER'].isin(infrequent_ner_tags)]\n",
    "data_cleaned.reset_index(drop=True, inplace=True)\n",
    "data_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45324, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token Distribution Summary:\n",
      "count    16247.000000\n",
      "mean         2.789684\n",
      "std          9.016175\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          2.000000\n",
      "max        442.000000\n",
      "Name: Token, dtype: float64\n",
      "\n",
      "POS Tag Distribution Summary:\n",
      "count       15.000000\n",
      "mean      3021.600000\n",
      "std       4578.532622\n",
      "min         19.000000\n",
      "25%        816.000000\n",
      "50%       1461.000000\n",
      "75%       3194.000000\n",
      "max      17803.000000\n",
      "Name: POS, dtype: float64\n",
      "\n",
      "NER Tag Distribution Summary:\n",
      "count       21.000000\n",
      "mean      2158.285714\n",
      "std       6643.519467\n",
      "min         12.000000\n",
      "25%        232.000000\n",
      "50%        460.000000\n",
      "75%       1151.000000\n",
      "max      30932.000000\n",
      "Name: NER, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Summary of distributions\n",
    "print(\"\\nToken Distribution Summary:\")\n",
    "print(token_distribution.describe())\n",
    "\n",
    "print(\"\\nPOS Tag Distribution Summary:\")\n",
    "print(pos_distribution.describe())\n",
    "\n",
    "print(\"\\nNER Tag Distribution Summary:\")\n",
    "print(ner_distribution.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Pad Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 15338\n"
     ]
    }
   ],
   "source": [
    "from bnlp import NLTKTokenizer\n",
    "\n",
    "bnltk = NLTKTokenizer()\n",
    "\n",
    "text = \"আমি ভাত খাই। সে বাজারে যায়। তিনি কি সত্যিই ভালো মানুষ?\"\n",
    "word_tokens = bnltk.word_tokenize(text)\n",
    "sentence_tokens = bnltk.sentence_tokenize(text)\n",
    "print(word_tokens)\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x248ed9dc9c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Vocabulary size: 16\n",
      "NER Vocabulary size: 14\n"
     ]
    }
   ],
   "source": [
    "# Initialize Tokenizer for POS tags\n",
    "tokenizer_pos = tf.keras.preprocessing.text.Tokenizer(lower=False, oov_token='<OOV>')\n",
    "tokenizer_pos.fit_on_texts(data_cleaned['POS'])\n",
    "\n",
    "# Convert POS tags to sequences\n",
    "pos_sequences = tokenizer_pos.texts_to_sequences(data_cleaned['POS'])\n",
    "pos_sequences = tf.keras.preprocessing.sequence.pad_sequences(pos_sequences, padding='post')\n",
    "\n",
    "# Initialize Tokenizer for NER tags\n",
    "tokenizer_ner = tf.keras.preprocessing.text.Tokenizer(lower=False, oov_token='<OOV>')\n",
    "tokenizer_ner.fit_on_texts(data_cleaned['NER'])\n",
    "\n",
    "# Convert NER tags to sequences\n",
    "ner_sequences = tokenizer_ner.texts_to_sequences(data_cleaned['NER'])\n",
    "ner_sequences = tf.keras.preprocessing.sequence.pad_sequences(ner_sequences, padding='post')\n",
    "\n",
    "# Print the size of the tokenizers' vocabularies\n",
    "print(f\"POS Vocabulary size: {len(tokenizer_pos.word_index)}\")\n",
    "print(f\"NER Vocabulary size: {len(tokenizer_ner.word_index)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token sequence length: 41\n",
      "POS sequence length: 1\n",
      "NER sequence length: 3\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Sequences have different lengths!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-98b89878738a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Verify that all sequences have the same length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpos_sequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mner_sequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Sequences have different lengths!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: Sequences have different lengths!"
     ]
    }
   ],
   "source": [
    "# Check lengths of sequences\n",
    "print(f\"Token sequence length: {sequences.shape[1]}\")\n",
    "print(f\"POS sequence length: {pos_sequences.shape[1]}\")\n",
    "print(f\"NER sequence length: {ner_sequences.shape[1]}\")\n",
    "\n",
    "# Verify that all sequences have the same length\n",
    "assert sequences.shape[1] == pos_sequences.shape[1] == ner_sequences.shape[1], \"Sequences have different lengths!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token sequences shape: (1, 45324)\n",
      "POS sequences shape: (1, 45324)\n",
      "NER sequences shape: (1, 45324)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Reset index to ensure proper grouping\n",
    "data_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add a unique sentence ID for grouping\n",
    "data_cleaned['sentence_id'] = data_cleaned.index.to_series().diff().ne(1).cumsum()\n",
    "\n",
    "# Group data by sentence_id\n",
    "grouped_data = data_cleaned.groupby('sentence_id')\n",
    "\n",
    "# Initialize lists for processed data\n",
    "token_sequences = []\n",
    "pos_sequences = []\n",
    "ner_sequences = []\n",
    "\n",
    "# Process each group (i.e., sentence) individually\n",
    "for _, group in grouped_data:\n",
    "    tokens = group['Token'].tolist()\n",
    "    pos_tags = group['POS'].tolist()\n",
    "    ner_tags = group['NER'].tolist()\n",
    "    \n",
    "    # Tokenize each list\n",
    "    token_seq = tokenizer_token.texts_to_sequences([tokens])[0]\n",
    "    pos_seq = tokenizer_pos.texts_to_sequences([pos_tags])[0]\n",
    "    ner_seq = tokenizer_ner.texts_to_sequences([ner_tags])[0]\n",
    "    \n",
    "    # Determine max length for padding\n",
    "    max_len = max(len(token_seq), len(pos_seq), len(ner_seq))\n",
    "    \n",
    "    # Pad sequences to ensure consistent length\n",
    "    token_seq = tf.keras.preprocessing.sequence.pad_sequences([token_seq], maxlen=max_len, padding='post')[0]\n",
    "    pos_seq = tf.keras.preprocessing.sequence.pad_sequences([pos_seq], maxlen=max_len, padding='post')[0]\n",
    "    ner_seq = tf.keras.preprocessing.sequence.pad_sequences([ner_seq], maxlen=max_len, padding='post')[0]\n",
    "    \n",
    "    # Append to lists\n",
    "    token_sequences.append(token_seq)\n",
    "    pos_sequences.append(pos_seq)\n",
    "    ner_sequences.append(ner_seq)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "token_sequences = np.array(token_sequences)\n",
    "pos_sequences = np.array(pos_sequences)\n",
    "ner_sequences = np.array(ner_sequences)\n",
    "\n",
    "# Print the shapes of the arrays to verify\n",
    "print(f\"Token sequences shape: {token_sequences.shape}\")\n",
    "print(f\"POS sequences shape: {pos_sequences.shape}\")\n",
    "print(f\"NER sequences shape: {ner_sequences.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
